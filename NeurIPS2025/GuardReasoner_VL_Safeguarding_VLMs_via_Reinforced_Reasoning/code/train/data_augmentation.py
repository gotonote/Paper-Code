import os
import json
import random
import argparse
from tqdm import tqdm
from PIL import Image
from io import BytesIO
from datasets import concatenate_datasets
from datasets import Dataset, DatasetDict


def concat_text(t1, t2):
    return (t1.strip() + ' ' + t2.strip()).strip()


def prompt_gt_mix(promtpt1, prompt2):
    if promtpt1=='harmful' and prompt2=='unharmful':
        return 'harmful'
    elif promtpt1=='unharmful' and prompt2=='harmful':
        return 'harmful'
    elif promtpt1=='harmful' and prompt2=='harmful':
        return 'harmful'
    elif promtpt1=='unharmful' and prompt2=='unharmful':
        return 'unharmful'


def res_gt_mix(promtpt1, prompt2):
    if promtpt1=='harmful' and prompt2=='unharmful':
        return 'harmful'
    elif promtpt1=='unharmful' and prompt2=='harmful':
        return 'harmful'
    elif promtpt1=='harmful' and prompt2=='harmful':
        return 'harmful'
    elif promtpt1=='unharmful' and prompt2=='unharmful':
        return 'unharmful'


def concat_images_with_padding(path1, path2, direction='horizontal', fill_color=(255, 255, 255), format='PNG', max_size=(1024, 1024)):
    img1 = Image.open(path1).convert('RGB')
    img2 = Image.open(path2).convert('RGB')

    w1, h1 = img1.size
    w2, h2 = img2.size

    if direction == 'horizontal':
        max_height = max(h1, h2)
        new_img1 = Image.new('RGB', (w1, max_height), fill_color)
        new_img2 = Image.new('RGB', (w2, max_height), fill_color)
        new_img1.paste(img1, (0, 0))
        new_img2.paste(img2, (0, 0))

        combined = Image.new('RGB', (w1 + w2, max_height), fill_color)
        combined.paste(new_img1, (0, 0))
        combined.paste(new_img2, (w1, 0))

    elif direction == 'vertical':
        max_width = max(w1, w2)
        new_img1 = Image.new('RGB', (max_width, h1), fill_color)
        new_img2 = Image.new('RGB', (max_width, h2), fill_color)
        new_img1.paste(img1, (0, 0))
        new_img2.paste(img2, (0, 0))

        combined = Image.new('RGB', (max_width, h1 + h2), fill_color)
        combined.paste(new_img1, (0, 0))
        combined.paste(new_img2, (0, h1))

    else:
        raise ValueError("Direction must be 'horizontal' or 'vertical'")

    combined.thumbnail(max_size, Image.Resampling.LANCZOS)
    
    buffer = BytesIO()
    combined.save(buffer, format=format)
    image_bytes = buffer.getvalue()
    
    image_data = {
        'bytes': image_bytes,
        'path': "aug",
    }
    
    return [image_data]


def mixup_sample(dataset, index1, index2):
    sample1 = dataset[index1]
    sample2 = dataset[index2]
    combined = concat_text(sample1['problem'], sample2['problem'])
    
    first_image_pos = combined.find("<image>")
    if first_image_pos != -1:
        second_image_pos = combined.find("<image>", first_image_pos + 1)
        if second_image_pos != -1:
            combined = combined[:second_image_pos] + combined[second_image_pos + len("<image>"):]
    
    if sample2['images'][0]['path'] == None:
        images = sample1['images']
    elif sample1['images'][0]['path'] == None:
        images = sample2['images']
    else:
        images = concat_images_with_padding(sample1['images'][0]['path'], sample2['images'][0]['path'])
    
    mixed = {
        'images': images,
        'problem': combined,
        'answer': concat_text(sample1['answer'], sample2['answer']),
        'prompt_gt': prompt_gt_mix(sample1['prompt_gt'], sample2['prompt_gt']),
        'response_gt': res_gt_mix(sample1['response_gt'], sample2['response_gt']),
    }
    return mixed


def generate_mixup_dataset(dataset, n_samples=1000):
    mixup_data = []
    for _ in tqdm(range(n_samples)):
        i1, i2 = random.sample(range(len(dataset)), 2)
        mix_sample = mixup_sample(dataset, i1, i2)
        mixup_data.append(mix_sample)
    return Dataset.from_list(mixup_data)


parser = argparse.ArgumentParser(description="rejection sampling")
parser.add_argument('--model_path', type=str, required=True, help='model path')
parser.add_argument('--data_path', type=str, required=True, help='data path')
parser.add_argument('--repeat_n', type=float, default=4, help='repeat n')
parser.add_argument('--sample_num', type=int, default=12000, help='number of sampling')
args = parser.parse_args()

save_dict_list = []

for data_name in ["GuardReasoner-VLTrainText", "GuardReasoner_VLTrainImage", "GuardReasoner_VLTrainTextImage"]:
    folder = args.model_path + data_name
    data_list = []
    
    for i in range(args.repeat_n):
        file = folder+f"/generated_predictions_{i}.jsonl"

        with open(file, "r") as f:
            data = [json.loads(line) for line in f]
            data_list.append(data)

    
    for id, item in enumerate(data_list[0]):
        if item['res_predict'] in ["None", "none"]:
            item['res_predict'] = "unharmful"

        all_mismatch = True
        for i in range(args.repeat_n):
            item_i = data_list[i][id]

            if item_i['res_predict'] in ["None", "none"]:
                item_i['res_predict'] = "unharmful"

            if item_i['label'] == item_i['predict'] and item_i['res_label'] == item_i['res_predict']:
                all_mismatch = False
                break  
            
        
        if data_name == "GuardReasoner_VLTrainImage":
            all_mismatch = True 
            
        if all_mismatch: 
            save_dict_list.append(item)


sampled_data = random.sample(save_dict_list, min(args.sample_num, len(save_dict_list)))

image_list = []
problem_list = []
answer_list = []
prompt_gt_list = []
res_gt_list = []


for id, item in enumerate(sampled_data):
    
    if "<image>" not in item["input"]:
        item["input"] = item["input"].replace('Human user:\n', 'Human user:\n<image>')
        image_list.append([Image.new("RGB", (1, 1), "white")])
    else:

        image_path = args.data_path+sample['images'][0][2:]
        with open(image_path, "rb") as img_file:
            image_bytes = img_file.read()

        image = Image.open(BytesIO(image_bytes))
        if max(image.size)>1024:
            print(image_path)

        image_data = {
            'bytes': image_bytes,
            'path': image_path,
        }

        image_list.append([image_data])

    
    problem_list.append(item["input"])
    answer_list.append(item["output_gt"])
    
    prompt_gt_list.append(item['label'])
    res_gt_list.append(item['res_label'])


data_dict = {
    "images": image_list,
    "problem": problem_list,
    "answer": answer_list,
    "prompt_gt": prompt_gt_list,
    "response_gt": res_gt_list
}

dataset = Dataset.from_dict(data_dict)


train_test_split = dataset.train_test_split(test_size=0.2, seed=42)

dataset = DatasetDict({
    "train": train_test_split["train"],
    "test": train_test_split["test"]
})


mix_data = generate_mixup_dataset(dataset["train"], n_samples=len(dataset["test"]))

dataset["train"] = concatenate_datasets([mix_data, dataset["train"]])

model_size = args.model_path.split("-")[-1].lower()

dataset["train"].to_parquet(f"{model_size}_aug_train.parquet")
dataset["test"].to_parquet(f"{model_size}_aug_val.parquet")
