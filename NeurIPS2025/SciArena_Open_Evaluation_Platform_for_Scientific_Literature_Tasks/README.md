# SciArena: An Open Evaluation Platform for Foundation Models in Scientific Literature Tasks

## 论文信息

- **标题**: SciArena: An Open Evaluation Platform for Foundation Models in Scientific Literature Tasks
- **作者**: Yale NLP Lab
- **会议**: NeurIPS 2025
- **GitHub**: [yale-nlp/SciArena](https://github.com/yale-nlp/SciArena)

## 核心内容

本文提出了 **SciArena**，一个用于评估基础模型在科学文献任务上表现的开放平台。

### 主要贡献

1. **综合评估平台**: 提供全面的科学文献任务评估框架。

2. **多任务覆盖**: 涵盖文献理解、信息提取、摘要生成等多种任务。

3. **开放基准**: 开放的数据集和评估代码，便于研究社区使用和改进。

### 技术细节

- **任务设计**: 多样化的科学文献处理任务
- **评估指标**: 全面的自动和人工评估指标
- **排行榜**: 公开的模型性能排行榜

## 代码结构

```
code/
├── datasets/        # 数据集
├── evaluation/     # 评估代码
├── models/         # 模型接口
└── README.md       # 原始 README
```

## 使用方法

请参考原始 GitHub 仓库中的说明。

## 注意事项

本代码为官方开源实现。
